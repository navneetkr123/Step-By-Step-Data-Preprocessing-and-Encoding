{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing_W2V_Encoding.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJRbAgki06u-",
        "colab_type": "text"
      },
      "source": [
        "# Extracting the zip file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxOL7nB8gf8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/Language_1.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/Language\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Fuwfyzu1GkS",
        "colab_type": "text"
      },
      "source": [
        "**Importing necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfyRz3vklpVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibjoYhQFvQMq",
        "colab_type": "text"
      },
      "source": [
        "#Labels \n",
        "**1 denotes positive sentiment and 0 denotes negative sentiment.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUWLYuS41Peq",
        "colab_type": "text"
      },
      "source": [
        "**reading files from amazon.txt**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQj-vbv2q-cc",
        "colab_type": "code",
        "outputId": "4a06dde5-2ef4-4852-fbe3-b5e79049f9e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df1 = pd.read_csv(\"/content/Language/Language_1/Round1_Problem1-of-2_Dataset_amazon_cells_labelled.txt\", header=None, delimiter=\"\\t\", names=[\"text\", \"sentiment\"])\n",
        "df1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93UcxfrxsL7x",
        "colab_type": "code",
        "outputId": "c0e0a10f-94d8-469e-bbb9-bc86c30cec46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df1.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment\n",
              "0  So there is no way for me to plug it in here i...          0\n",
              "1                        Good case, Excellent value.          1\n",
              "2                             Great for the jawbone.          1\n",
              "3  Tied to charger for conversations lasting more...          0\n",
              "4                                  The mic is great.          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siQrLjT61TSH",
        "colab_type": "text"
      },
      "source": [
        "**reading files from imdb.txt**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHUIbbGhq-e7",
        "colab_type": "code",
        "outputId": "67c09a20-16c2-44a8-8708-bcd33500441a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df2 = pd.read_csv(\"/content/Language/Language_1/Round1_Problem1-of-2_Dataset_imdb_labelled.txt\", header=None, delimiter=\"\\t\",names=[\"text\", \"sentiment\"])\n",
        "df2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(748, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfNKzobOr12K",
        "colab_type": "code",
        "outputId": "c226253d-57b3-4e1a-fd2f-edbe018f81a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df2.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not sure who was more lost - the flat characte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Very little music or anything to speak of.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The best scene in the movie was when Gerardo i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment\n",
              "0  A very, very, very slow-moving, aimless movie ...          0\n",
              "1  Not sure who was more lost - the flat characte...          0\n",
              "2  Attempting artiness with black & white and cle...          0\n",
              "3       Very little music or anything to speak of.            0\n",
              "4  The best scene in the movie was when Gerardo i...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ5A2ehh0_EX",
        "colab_type": "text"
      },
      "source": [
        "# Merging both the dataframe as one with text and sentiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLp__AybzoWA",
        "colab_type": "code",
        "outputId": "0b8fce05-8dc2-4d67-82e2-85fc862a22c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "frames = [df1, df2]\n",
        "df = pd.concat(frames, axis =0)\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1748, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ucqgzmB0Zki",
        "colab_type": "code",
        "outputId": "e0a87529-c73f-446e-abcd-9d8ec536779b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment\n",
              "0  So there is no way for me to plug it in here i...          0\n",
              "1                        Good case, Excellent value.          1\n",
              "2                             Great for the jawbone.          1\n",
              "3  Tied to charger for conversations lasting more...          0\n",
              "4                                  The mic is great.          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuUkAnC62BvD",
        "colab_type": "text"
      },
      "source": [
        "**visualizing 5 full list values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR7lv5LA4Ksy",
        "colab_type": "code",
        "outputId": "65ee197a-b541-470b-ea76-0ab613da5059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df.text.tolist()[1:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Good case, Excellent value.',\n",
              " 'Great for the jawbone.',\n",
              " 'Tied to charger for conversations lasting more than 45 minutes.MAJOR PROBLEMS!!',\n",
              " 'The mic is great.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJpFfov01gSG",
        "colab_type": "text"
      },
      "source": [
        "# removing html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2dIB10Y1gco",
        "colab_type": "code",
        "outputId": "6e417647-7de1-4d82-a399-31fee9785602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Regex (Regualar Expr Operations)\n",
        "import re \n",
        "\n",
        "#Function to remove html tags from data\n",
        "def removehtml(data):\n",
        "    p = re.compile('<.*?>')#Find this kind of pattern\n",
        "    #print(p.findall(data))#List of strings which follow the regex pattern\n",
        "    return p.sub('',data) #Substitute nothing at the place of strings which matched the patterns\n",
        "\n",
        "#Checking with my own html if this works or not  \n",
        "removehtml('<a href=\"foo.com\" class=\"bar\">My name is Navneet <b>, Hello!</b></a><>')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'My name is Navneet , Hello!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls-qWUmk2WEV",
        "colab_type": "text"
      },
      "source": [
        "**removing all html from text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4EOachV2EcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_without_html = []\n",
        "for i in df.text.values:\n",
        "  sentence = removehtml(i)\n",
        "  text_without_html.append(sentence)\n",
        "  \n",
        "df.text = text_without_html  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltCy8gXk32wr",
        "colab_type": "code",
        "outputId": "339712de-c08c-44a2-e106-acb20a564b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "text_without_html[975:980]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['It is the best charger I have seen on the market yet.',\n",
              " 'SWEETEST PHONE!!!',\n",
              " ':-)Oh, the charger seems to work fine.',\n",
              " 'It fits so securely that the ear hook does not even need to be used and the sound is better directed through your ear canal.',\n",
              " 'Not enough volume.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CXHxh0N7kH9",
        "colab_type": "text"
      },
      "source": [
        "# Remove website links"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI02g5Mo2fYk",
        "colab_type": "text"
      },
      "source": [
        "**checking with my own strings if this works or not and hopefully it worked**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh81G8q5tmP8",
        "colab_type": "code",
        "outputId": "574e22c2-0058-4071-f4ac-59690f3dd713",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "lis = [\"hello www.xyz.com\"]\n",
        "f = pd.DataFrame(lis, columns=[\"one\"])\n",
        "f = f.one.str.replace(\"www.\\S+\", \" \", case=False)\n",
        "f"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    hello  \n",
              "Name: one, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjeAXOgu2o_9",
        "colab_type": "text"
      },
      "source": [
        "**removing html links from text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JONOecQG7kTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['text'] = df['text'].str.replace('www.\\S+', '', case=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui0-2IPK_RJ2",
        "colab_type": "text"
      },
      "source": [
        "# Convert\tmajor\temoticons\tto\ttheir\trespective\temotions\t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs7_bpTV2vqM",
        "colab_type": "text"
      },
      "source": [
        "**checking two rows with smily faces**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjYW33oTWJRh",
        "colab_type": "code",
        "outputId": "71c2dd56-676c-4006-aa50-d71712bdee0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(df.text[387])\n",
        "print(df.text[977])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "387    The best phone in market :).\n",
            "387              Not recommended.  \n",
            "Name: text, dtype: object\n",
            ":-)Oh, the charger seems to work fine.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oti1gv4k25R7",
        "colab_type": "text"
      },
      "source": [
        "**converting smily faces with replace**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_V6DxnIjOhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"text\"] = df[\"text\"].replace([\"\\:\\)\", \"\\:\\-\\)\", \"\\:\\-\\}\", \"\\;\\-\\}\", \"\\:\\-\\>\", \"\\;\\-\\)\"], [\"Happy\",\"Happy\",\"Happy\",\"Happy\",\"Happy\",\"Happy\"], regex=True)\n",
        "df[\"text\"] = df[\"text\"].replace([\"\\:\\-\\(\", \"\\:\\(\", \"\\:\\-\\|\", \"\\;\\-\\(\", \"\\;\\-\\<\", \"\\|\\-\\{\"], [\"Sad\", \"Sad\", \"Sad\", \"Sad\", \"Sad\", \"Sad\",], regex=True)\n",
        "df[\"text\"] = df[\"text\"].replace([\"\\:\\D\", \"\\:\\'\\-\\)\", \"\\:\\`\\-\\(\"], [\"laugh\", \"tear of joy\", \"tear of sadness\"], regex=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPVJc6Wq2-Y_",
        "colab_type": "text"
      },
      "source": [
        "**we can see below that all smiley faces have been repaced by therir respective meaning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg5iitVYV5Zw",
        "colab_type": "code",
        "outputId": "33954bdd-c643-4dd4-d9d6-25f6c65a5781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(df.text[387])\n",
        "print(df.text[977])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "387    The best phone in market Happy.\n",
            "387                 Not recommended.  \n",
            "Name: text, dtype: object\n",
            "HappyOh, the charger seems to work fine.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLcWQr1guU4-",
        "colab_type": "text"
      },
      "source": [
        "# Removing all punctuation except few\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSXZmLak2ka1",
        "colab_type": "code",
        "outputId": "b24dad67-fb7d-4450-9da7-4d7f35bcfcad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df[\"text\"].tolist()[14]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The design is very odd, as the ear \"clip\" is not very comfortable at all.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO9BevNt3MCs",
        "colab_type": "text"
      },
      "source": [
        "**here final represents all punctuations except . ! and ,**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9cHq3GQulCv",
        "colab_type": "code",
        "outputId": "856abc24-3df3-4a21-9659-94f3501481db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import string\n",
        "exclude = set(string.punctuation)\n",
        "not_exclude={\".\", \"!\", \",\"}\n",
        "final = exclude-not_exclude\n",
        "\n",
        "print(len(exclude))\n",
        "print(len(not_exclude))\n",
        "print(len(final))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "3\n",
            "29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSJ9vJcYw_CN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in final:\n",
        "  df['text'] = df['text'].str.replace(i, '', regex=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxMD3pxe3YFE",
        "colab_type": "text"
      },
      "source": [
        "**we can see that punctuation \"clip \" is replaced by clip.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDiU_JB_ygmD",
        "colab_type": "code",
        "outputId": "1057952a-f7e7-4bb3-dd5c-6d5b4764230c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df[\"text\"].tolist()[14]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The design is very odd, as the ear clip is not very comfortable at all.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK8rV-hi3j4M",
        "colab_type": "text"
      },
      "source": [
        "# Removing major stop words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiEFkUti9uI_",
        "colab_type": "text"
      },
      "source": [
        "**downloading stopwords**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4PxICoV3kDx",
        "colab_type": "code",
        "outputId": "877ecca1-d3ec-4802-97d0-401eb2e2cbfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXIult2P90rh",
        "colab_type": "text"
      },
      "source": [
        "**extending stopwords with nltk_words to remove maximum unnecessary words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh5CkIp_sza9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip3 install stop_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTAQQlER7fIC",
        "colab_type": "code",
        "outputId": "14701382-e187-4da1-89c2-35cf64e7796a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#https://stackoverflow.com/questions/5486337/how-to-remove-stop-words-using-nltk-or-python\n",
        "from stop_words import get_stop_words\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = list(get_stop_words('en'))         #About 900 stopwords\n",
        "nltk_words = list(stopwords.words('english')) #About 179 stopwords\n",
        "stop_words.extend(nltk_words)\n",
        "\n",
        "len(stop_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "353"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3fSm6Sl5X1L",
        "colab_type": "code",
        "outputId": "cd9bc661-8278-4445-adaa-2ca450ec4bca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Combining all the above stundents \n",
        "from tqdm import tqdm\n",
        "preprocessed_text = []\n",
        "# tqdm is for printing the status bar\n",
        "for sentance in tqdm(df['text'].values):\n",
        "    sent = ' '.join(e for e in sentance.split() if e not in stop_words)\n",
        "    preprocessed_text.append(sent.lower().strip())\n",
        "\n",
        "df[\"text\"] = preprocessed_text    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1748/1748 [00:00<00:00, 18149.38it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9brolpb3o3o",
        "colab_type": "text"
      },
      "source": [
        "**below we can see that all the stop words have been removed**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSXD-hdI53W2",
        "colab_type": "code",
        "outputId": "4efa1d3a-b861-4c9d-965e-bcb261b85ea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df.text.tolist()[5:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i jiggle plug get line right get decent volume.',\n",
              " 'if several dozen several hundred contacts, imagine fun sending one one.',\n",
              " 'if razr owner...you must this!',\n",
              " 'needless say, i wasted money.',\n",
              " 'what waste money time!.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp0iRgfC-DyU",
        "colab_type": "text"
      },
      "source": [
        "# Lemmatize\tall\tthe\twords."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzYRTAKGzrFW",
        "colab_type": "code",
        "outputId": "4af03321-0603-41fd-f7e7-e88c3874db50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer \n",
        "  \n",
        "lemmatizer = WordNetLemmatizer() \n",
        "\n",
        "lemet_text = []\n",
        "# tqdm is for printing the status bar\n",
        "for sentance in tqdm(df['text'].values):\n",
        "    sent = ' '.join(e for e in sentance.split() if e in stemmer.stem(e) )\n",
        "    lemet_text.append(sent.lower().strip())\n",
        "\n",
        "df[\"text\"] = lemet_text    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1748/1748 [00:00<00:00, 7083.25it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgHcTmTZ30qJ",
        "colab_type": "text"
      },
      "source": [
        "**we can see below that all words are in their lematized form**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxgDNaJzzrNa",
        "colab_type": "code",
        "outputId": "715715f4-2389-4505-c86e-abe08b4b140e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df.text.tolist()[5:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i plug get line right get decent volume.',\n",
              " 'if dozen contacts, fun one one.',\n",
              " 'if razr owner...you must this!',\n",
              " 'needless say, i money.',\n",
              " 'what money time!.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oo_bCoTCdTm",
        "colab_type": "text"
      },
      "source": [
        "# Tokenize\tthe\tdata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q9dFyAvCi4r",
        "colab_type": "code",
        "outputId": "49c86c13-3f9f-4e23-950e-38b51b562d6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "df['text'] = df.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAMfpWx_Jtl7",
        "colab_type": "code",
        "outputId": "7564a33c-9f1d-4150-876b-6d69d3d6f6a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df.text.tolist()[5:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['i', 'plug', 'get', 'line', 'right', 'get', 'decent', 'volume', '.'],\n",
              " ['if', 'dozen', 'contacts', ',', 'fun', 'one', 'one', '.'],\n",
              " ['if', 'razr', 'owner', '...', 'you', 'must', 'this', '!'],\n",
              " ['needless', 'say', ',', 'i', 'money', '.'],\n",
              " ['what', 'money', 'time', '!', '.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95RBYoJPL_VH",
        "colab_type": "text"
      },
      "source": [
        "# converting\tthe\tdata\tinto\tvector\tforms\tusing\tWord2Vec\twith\tvector\tsize\tof\t20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iteXxdMtMd1B",
        "colab_type": "code",
        "outputId": "e1cca245-25f9-4e17-ec2c-cef6ac1f4ef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "# train model\n",
        "model = Word2Vec(df.text.values, min_count=1, size = 20)\n",
        "# summarize the loaded model\n",
        "print(model)\n",
        "# summarize vocabulary\n",
        "words = list(model.wv.vocab)\n",
        "print(words)\n",
        "# access vector for one word\n",
        "print(model['plug'])\n",
        "# save model\n",
        "model.save('model.bin')\n",
        "# load model\n",
        "new_model = Word2Vec.load('model.bin')\n",
        "print(new_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=2674, size=20, alpha=0.025)\n",
            "['so', 'way', 'plug', 'us', 'unless', 'i', 'go', 'converter', '.', 'good', 'case', ',', 'value', 'great', 'jawbone', 'charger', '45', 'minutes.major', 'problems', '!', 'the', 'mic', 'get', 'line', 'right', 'decent', 'volume', 'if', 'dozen', 'contacts', 'fun', 'one', 'razr', 'owner', '...', 'you', 'must', 'this', 'needless', 'say', 'money', 'what', 'time', 'and', 'sound', 'he', 'battery', 'two', 'mere', '5', 'ft', 'static', 'headset', 'though', 'design', 'odd', 'ear', 'clip', 'all', 'recommend', 'blue', 'tooth', 'phone', 'do', 'not', 'be', 'fooled', 'far', 'it', 'place', 'wonder', 'long', 'last', 'went', 'directions', 'pair', 'again', 'bought', 'use', 'fire', 'misleading', 'yet', 'run', 'new', 'three', 'without', 'charging', 'mother', 'problem', 'pocket', 'pc', 'combination', 'ive', '7', 'best', 'had', 'didnt', 'think', 'me', 'couldnt', 'hear', 'talk', 'pull', 'doesnt', 'hold', 'charge', 'unacceptible', 'product', 'ideal', 'like', 'whose', 'sensitive', 'car', 'freeway', 'speed', 'left', 'contract', 'hate', 'well', 'ac', 'make', 'sure', 'never', 'need', 'least', '3', 'book', 'first', 'turn', 'life', 'short', 'kept', 'poor', 'performance', 'fine', '680', 'worthless', 'camera', '2mp', 'nice', 'clear', 'quality', 'audio', 'bluetooth', 'want', 'who', 'mind', 'gon', 'na', 'buy', 'after', 'with', 'verizon', 'we', 'days', 'made', 'loud', 'enough', 'should', 'bulky', 'a', 'keyboard', 'pda', 'realworld', 'instead', 'neat', 'gadget', 'love', 'thing', 'price', 'i.e', 'disappointed', 'even', 'stream', '15', 'still', '510', 'no', 'end', 'bad', 'forget', 'tech', 'support', 'cool', 'these', 'find', 'seriously', 'particular', 'clearly', 'big', 'drawback', 'mp3', 'player', 'front', 'cover', 'let', 'skip', 'lock', 'seconds', 'week', 'later', 'died', 'wear', 'sometimes', 'too', 'situations1', 'work', 'bmw', 'quiet', 'person', 'saying', 'choice', 'station', 'home', 'd807', 'item', 'lot', 'within', '2', 'longer', 'working', 'everyday', 'bargain', 'packaged', 'intended', 'quickly', 'broke', '6', 'them', 'better', 'boy', 'cheaper', 'super', 'for', 'much', 'does', 'expect', 'greater', 'sturdy', 'play', 'music', 'dont', 'will', 'order', 'plan', 'found', 'waaay', 'using', 'im', 'decision', 'motorola', 'buyer', 'beware', 'flush', 'toilet', 'free', 'purchase', '375', 'match', 'proslaughgood', 'also', 'black', 'white', 'more', 'huge', 'flaw', 'correctly', '350', 'headset..', 'my', 'jabra350', 'fit', 'although', '1.3', 'megapixels', 'fall', 'high', 'resolution', 'excellent', 'call', 'wife', 'ask', 'slim', 'light', 'display', 'beautiful', 'sex', 'toast', 'sleek', 'stylish', 'leather', 'fast', 'shipping', 'full', 'basic', 'cell', 'number', 'keypad', 'got', 'around', 'may', 'winner', 'setup', 'simpler', 'jabra', 'comfortably', 'could', 'strong', 'signal', 'iam', 'job', 'done', 'set', 'weeks', 'bt', 'disapoinment', 'small', 'almost', 'brilliant', 'avoid', 'damage', 'careful', 'logitech', 'earbud', 'failed', 'stuff', 'peachykeen', 'in', 'basement', 'tremendous', 'waste', 'calls', 'area', 'bars', 'literally', 'glad', 'did', 'are', 'included', 'months', 'screen', 'sudden', 'was', '8530', 'curve', 'know', 'funny', 'wouldnt', 'well.well', 'kind', 'web', 'faster', 'previous', 'used', 'build', 'cheap', 'there', 'perfectly', 'colors', 'w810i', 'superb', 'whine', 'internet', 'less', 'tool', 'communicate', 'charm', 'maintain', 'shouldnt', 'headphones', 'share', 'dna', 'humans', 'all..', 'bougth', 'l7c', 'look', 'sharp', 'graphics', 'mode', 'button', 'side', 'service', 'thank', 'how', 'igo', 'file', 'browser', 'network', 'hs850', 'whether', 'put', 'latest', 'os', 'v1.15g', 'slow', 'crawl', 'while', 'device', 'conversations', 'bluetoooth', 'awesome', 'thorn', 'abhor', 'stay', '10', 'disconnected', 'incredible', '13', 'bucks', 'but', 'check', 'mail', 'night', 'backlight', 'message', 'lost', 'ring', 'buy..', 'wit', 'hit', 'impressed', 'weight', 'youll', 'thin', 'is', 'pleather', 'useless', 'deaf', 'color', 'prettier', 'thought', 'investment', 'fm', 'transmitters', 'hours', 'h500', '1.2', 'mega', 'pixel', 'part', 'good7', 'transmit', 'back', 'bother', 'dollar', 'lesson', 'form', 'anyway', 'earbugs', 'means', 'roam', 'room', 'receptionsound', 'issues', 'felt', 'crack', 'worst', 'ever', 'frequently4', 'simple', 'lightweight', 'id', 'tick', 'background', 'before', 'mess', 'hair', 'bit', 'year', 'now', 'tell', 'ericsson', 'market', 'shine', 'comfort', '.i', 'cute', 'calendar', 'sync', 'provided', 'whatsoever', 'worth', 'penny', 'wallet', 'type', 'aspect', 'glove', 'secure', 'durable', 'o', 'gosh', 'factor', 'rubberpetroleum', 'smell', 'return', 'flimsy', 'scary', 'earpiece', 'stereo', 'month', 'absolutel', 'junk', 'that', 'either', 'real', '8', 'drain', 'up', 'gave', 'can', 'feature', 'helpful', 'whole', 'family', 'seller', 'plantronics', 'adorable', 'contstruct', 'hinge', 'thru', 'handset', 'cat', 'strip', 'terrible', 'razor', 'v3i', 'wise', 'sooner', 'clever', 'has', 'as', 'complained', 'weak', '5year', 'old', 'nokia', '2160', 'they', 'care', 'manual', 'lacking', 'alarm', 'clock', 'antena', 'lg', 'gotten', 'state', 'allow', 'driving', 'immediately', 'ngage', 'earbuds', '23', 'cant', 'anything', 'low', 'neither', 'games', 'amazon', 'sucks', 'rip', 'over', 'comfortable', 'came', 'ago', 'ipod', '1.', 'flip', 'phones2', 'adhesive', 'disappointing', 'piece', 'add', 'boost', 'happy', 'of', 'on', 'knock', 'wood', 'easier', 'vehicle', 'belt', 'were', 'charm..', 'advertised', 'range', 'their', 'los', 'horrible', 'starter', 'wireless', 'option', 'appealing', 'hot', 'everything', 'dropped', 'save', 'face', 'down', 'transmission', 's11', 'data', 'cable', 'happier', 'ill', 'drivng', 'along', 'reason', 'item..', 'auto', 'tape', 'hurt', 'push', 'sides', 'skype', 'soyo', 'take', 'self', 'exterior', 'same', 'mentioned', 'help', 'crap', 'wanted', 'today', 'deal', 'give', 'try', 'youd', 'earpieces', 'effective', 'waiting', 'well..', 'prompt', 'stupid', 'keep', 'chargers', 'cradles', 'out', 'cingulair', 'nicer', 'phones', 'everyone', 'era', 'dead', 'years', 'an', '2000', 'att', 'yell', 'plastic', 'oh', 'forgot', 'mention', 'weird', 'effect', 'spinn', 'unit', 'fond', 'strap', 'overall', 'reception', 'note', 'rather', 'bland', 'model', 'easy', 'sanyo', 'blacktop', 'earphones', 'away', 'enter', 'modest', 'cellular', 'wish', '1', '12', 'dying', 'earpad', 'only.i', 'anyone', 'displeased', 'might', 'defect', 'risk', 'built', 'alone', 'difficult', 'install', 'jx10', 'moto', 'q', 'figure', 'size', 'key', 'pad', 'lit', 'hard', 'wasnt', 'priced', 'works', 'reception.a', 'expensive', 'bed', 'wifi', '20', 'morning', 'card', 'hat', 'sunglasses', 'shipment', 'solid', 'gx2', 'bt50', 'others', 'computer', 'clarity', 'accessoryone', 'carriers', 'cumbersome', 'disappointment..', 'motorolas', 'vx9900', 'env', 'switch', 'unknown', 'bills', 'however', 'understand', 'overnight', 'wont', 'regret', 'disappointment', 'user', 'friendly', 'respect', 'then', 'stuck', 'max', 'mute', 'rocks', 'hybrid', 'palmtopcameracellphone', 'roles', 'bt250v', 'wrong', 'described', '11', 'satisfied', 'bose', 'amazing', 'nyc', 'commuter', 'given', 'star', 'able', 'unacceptable.unless', 'nothing', 'holster', 'photo', 'ad', 'earlier', 'review', 'noted', 'happens', 'frog', 'eye', 'catching', 'function', 'aluminum', 'palm', 'vx', 'wellit', 'handheld', 'have', 'timeframe', 'source', 'waterproof', 'complaint', 'standard', '5of', 'store', 'ugly', 'times', 'shield', 'incrediable', 'improvement', 'refund', 'replace', 'gentletouch', 'touch', 'listening', 'threw', 'window', 'took', 'drop', 'kitchen', 'counter', 'cracked.i', 'laughing', 'trunk', 'hitch', 'looking', 'channel', 'seem', 'none', 'properly', 'defective', 'sucked', 'shifting', 'bubbling', 'peeling', 'scratch', 'droid', 'zero', 'would', 'frustration', 'earset', 'outgoing', 'total', 'package', 'patient', 'star.i', 'contact', 'cingularatt', 'inform', 'practice', 'aggravating', 'friends', 'enjoy', 'virgin', 'muddy', 'insert', 'slid', 'off', 'isnt', 'results', 'expected', '..', 'fourth', 'hated', 'functions', 'unacceptable', 'joke', 'said', 'due', 'stop', 'procedures', 'reset', 'strength', 'louder', 'speaker', 'constructed', 'menus', 'navigate', 'on.id', 'broken', 'smoking', 'sprint', 'effort', 'than', 'idea', 'trash', 'research', 'doing', 'killer', 'breaking', 'those', 'construction', 'infuriating', 'walkman', 'feel', 'asia', '50', 'upandcoming', '5020', '24', 'day', 'pain', 'quick', 'fraction', 'samsung', 'e715..', 'seeen', 'instructions', 'designs', 'treo', '700w', 'usb', 'transceiver', 'steer', 'replacementr', 'pens', 'come', 'threepack', 'buyit', 'fingers', 'plus', 'steep', 'point', 'apart', 'haul', 'brand', 'extra', 'phonesmp3', 'grey', 'red', 'needed', 'pay', 'guess', 'cds', 'connection', 'fabulous', 'firstperson', 'delay', 'bitpim', 'program', 'internetto', 'transfer', 'manufacturer', 'muffled', 'echo', 'windresistant', 'forever', 'tried', 'told', 'warranty', 'receipt', 'luck', 'refurb', 'something', 'bar', 'when', 'snug', 'pleased', 'heavy', 'utter', 'crap..', 'loop', 'finally', 'four', 'spring', 'latch', 'visor', 'download', 'address', 'reboots.overall', 'rate', 'tinny..', 'tungsten', 'e2', 'flipphones', 'picture', 'smoothly', 'access', 'handy', 'somehow', 'dropping', 'upload', 'third', 'party', 'flash', 'locked', 'awful', '325', 'cellphone', 'wornout', 'ringer', 'acceptable', 'prime', 'looks', 'upbeat', 'abound', 'explain', 'jack', 'ca42', 'crisp', 'smallest', 'biggest', 'superfast', 'stand', 'video', 'clips', 'occupied', 'hour', 'accept', 'except', 'cbr', 'mp3s', 'media', 'beat', 'shots', 'sos', 'connect', 'miniusb', 'near', 'conversation', 'open', 'startac', 'since', 'outperform', 'china', 'v325i', 'sim', '3o', 'minutes', 'r', 'replaced', 'quit', '18', 'owned', '4s', 'power', 'imac', 'wall', 'outlet', 'etc', 'mediocre', 'via', 'slide', 'grip', 'hand', 'span', 'exclaim', 'whoa', 'tv', 'freedom', 'mark', '100', 'functional', 'other', 'soft', 'tight', 'cut', 'shape', 'copier', 'sent', 'ears', 'anywhere', 'sold', 'months..', 'pros', 'classy', 'krussel', 'toactivate', 'good.4', 'texas', 'dit', '5320', 'soon', 'purchasing', 'next', 'blueant', 'supertooth', 'metro', 'pcs', 'schr450', 'slider', 'premium', 'plugs', 'capacity', 'somewhat', 'ant', 'hey', 'works..', 'cost', 'dustpan', 'indoors', 'puff', 'smoke', 'ride', 'smoother', 'nano', 'son', 'dissapointed', 'reccommend', 'highest', 'protector', 'date', 'just', 'smartphone', 'atleast', 'amp', 'reoccure.bottom', 'else', 'cingular', 'wooden', 'floor', 'apartment', 'boot', 'worthwhile', 'discount', 'break', 'entertainment', 'communication', 'management.oh', 'activesync', '4.2', 'disgusting', 'another', 'coupon', 'rare', 'worked', 'perfect', 'ps3', 'five', 'bargain..', 'wind', 'yes', 'at', 'grtting', '7.44', 'v3c', 'together', 'feet', 'sight', 'description', 'awkward', 'unreliable', 'hoped', 'father', 'v265', 'intermittently', 'bottom', 'row', 'uncomfortable', 'send', 'be.3', 'nightmare', 'speakerphone', 'terrible..', 'cassette', 'current', 'from', 'dirty', 'autoanswer', 'read', 'havent', 'sensor', 'reliability', 'beeping', 'dieing', 'laptop', 'ir', 'years.great', 'cancellation', 'hands', 'counterfeit', 'good..', 'see', 'swivel', 'sister', '8125', 'inside', 'bottowm', 'gimmick', 'iphone', 'opens', 'top', 'discomfort', 'trust', 'loud.glad', 'flawless', 'normal', 'tips', 'fails', 'wrong.first', 'lose', 'very', 'holder', 'easily', 'flaws', 'oem', 'loudest', 'setting', 'competitors', 'show', 'alot', 'beep', 'ok', 'unintelligible', 'word', 'restart', 'bend', 'leaf', 'metal', 'stress', 'leopard', 'print', 'wild', 'saggy', 'cases', 'soundwise', 'snap', '8525', 'fliptop', 'seat', 'fact', 'lap', 'accessable', 'mine', 'rest', 'otherwise', 'joy', 'company', '2005', 's710a', 'wow', 'it..', 'armband', 'allot', 'clearer', 'reach', 'buttons', 'ericson', 'z500a', 'to', 'motor', 'control', 'center', 'equipment', 'certain', 'places', 'girl', 'complain', 'wake', 'fee', 'darn', 'seen', 'sweetest', 'happyoh', 'hook', 'canal', 'hype', 'mistake', 'covered', 'text', 'blew', 'junk..', 'disappoint', 'infra', 'port', 'irda', 'answer', 'once', 'slowmoving', 'aimless', 'distressed', 'young', 'man', 'flat', 'audience', 'half', 'angles', 'plot', 'nonexistent', 'speak', 'scene', 'gerardo', 'song', 'head', 'art', 'meaning', 'emptiness', 'empty', 'saw', 'kids', 'predictable', 'buffet', 'teacher', 'florida', 'hilarious', 'main', 'budget', 'overdue', 'tale', 'greatest', 'film', 'gem', 'screenplay', 'cinematography', 'acting', 'postproduction', 'editing', 'directing', 'filmmaking', '\\x96', 'true', 'sea', 'faux', 'masterpieces', 'cinema', 'minute', 'words', 'content', 'level', 'fill', 'films', 'imaginable', 'amount', 'puzzlesolving', 'punches', '0', 'game', 'th', 'series', 'levels', 'characters', 'actually', 'canada', 'aye', 'pure', 'brilliance', 'flick', 'conception', 'lame', 'minor', 'pg13', 'nonsequel', 'tone', 'movie', 'interested', 'confirm', 'generic', 'moment', 'trailer', 'his', 'fare', 'morgan', 'freeman', 'jonah', 'hill', 'ed', 'wasted', 'lazy', 'animals', 'obvious', 'bluegreenscreen', 'despite', 'lesser', 'written', 'french', 'cancan', 'cutest', 'grace', 'negative', 'insipid', 'pointless', 'efforts', 'cast', 'performances', 'believable', 'convincing', 'sam', 'gung', 'ho', 'sobering', 'sat', '9', 'tom', 'actor', 'children', 'little', 'chalkboard', 'coaster', 'warmth', 'nerves', 'improvisation', 'twice', 'aboutlaughnot', 'honestly', 'often', 'follow', 'surroundings', 'unpredictable', 'badly', 'cross', 'g', 'pg', 'movies', 'predict', 'dialog', 'verbatim', 'selections', 'gross', 'chills', 'artist', 'whoever', 'lived', 'stratus', 'arent', 'québec', 'wordofmouth', 'promote', 'thoughtprovoking', 'lion', 'acted', 'classic', 'blist', 'script', 'horrendous', 'manna', 'heaven', 'going', 'veteran', 'nostalgia', 'trip', 'ursula', 'nun', 'church', 'shirley', 'tonight', 'ending', 'frankly', 'cotton', 'club', 'unfaithful', 'watch', 'lane', 'gere', 'shallow', 'insincere', 'chick', 'correct', 'house', 'lousy', 'bring', 'fresh', 'bold', 'boring', 'paper', 'columbo', 'pretentious', 'neighbourgirl', 'misplace', 'weaker', 'episode', 'sack', 'murder', 'horror', 'some', 'director', 'afraid', '1010', 'villain', 'rent', 'michael', 'ironside', 'world', 'social', 'outlets', 'ben', 'affleck', 'sandra', 'bullock', 'by', 'moving', 'wedding', 'fear', 'i.q', 'imdb', 'mirrormask', 'experience', 'unfortunately', 'meant', 'tension', 'conflict', 'central', 'ineptly', 'depth', 'imagination', 'core', 'bunch', 'hell', 'cult', 'disaster', 'incredibly', 'fish', 'thousand', 'truly', 'worse', 'mst3k', 'fodder', 'paid', 'treat', 'quinn', 'horse', 'walk', 'relief', 'yeah', 'or', 'storyline', 'pillow', 'girlfriendboyfriend', 'gone', 'mad', '7.50', 'cardboard', 'reversestereotypes', 'writing', 'actors', '.an', 'cartoon', 'paul', 'storytelling', '.a', 'crayons', 'crash', 'emotion', 'racism', 'things', 'women', 'your', 'brain', 'attempt', 'shutdown', 'primal', 'selfpreservation', 'recover', 'boogeyman', 'zombiez', 'hellish', 'mean', 'features', 'appalling', 'artless', 'camerawork', 'ugliest', 'beyond', 'annoying', 'lead', 'charismafree', 'merit', 'akin', 'torture', 'atrocity', 'pleasant', 'selfdiscovery', 'unrecommended', 'ms', 'garbo', 'bat', 'silent', 'netflix', 'marion', 'hasnt', 'step', 'suspense', 'close', 'ups', 'drag', 'ones', 'age', 'john', 'industry', 'senior', 'him', 'older', 'hadnt', 'spent', 'noteworthy', 'gallon', 'blood', 'spew', 'forth', 'foxx', 'ray', 'charles', 'genius', 'spacek', 'coal', 'daughter', 'quaid', 'himself', 'legendary', 'musician', 'hitchcock', 'secondly', 'thriller', 'chase', 'energy', 'machine', 'scenes', 'usual', 'logic', 'mishima', 'uninteresting', 'chilly', 'author', 'culture', 'adrift', 'stagy', 'purity', 'swords', 'bore', 'pieces', 'kill', 'momentum', 'quicker', 'schrader', 'amateurish', '80s', 'dancing', 'dvd', 'struck', 'holes', 'horrid', 'ballet', 'repertory', 'pathetic', 'woa', 'sappiest', 'dialogue', 'direction', 'talent', 'action', 'site', 'chance', 'master', 'themeat', 'theme', 'worldweariness', 'aerial', 'regrettably', 'visual', 'interest', 'drama', 'feeling', 'narrative', 'actress', 'june', 'allison', 'plain', 'cinematographyif', 'thatsucked', 'soundtrack', 'concert', 'angry', 'crafted', 'fx', 'stateoftheart', 'conceptually', 'parents', 'andor', 'fans', 'sour', 'actingwise', 'casting', 'here', 'considered', 'released', 'mexican', 'understood', 'themselves', 'matter', 'noircrimedrama', 'belmondo', 'lino', 'ventura', 'character', 'complex', 'portrayals', 'loyalty', 'treachery', 'hope', 'melville', 'journey', 'soul', 'child', 'water', 'transcend', 'gripping', 'swamp', 'eccleston', 'succeeded', 'forced', 'theater', 'sick', 'werent', 'witty', 'bob', 'rise', 'ratinglaugh1', 'kieslowski', 'directors', 'flag', 'shot', 'spoiler', 'dealt', 'smile', 'wrap', 'trilogy', 'pearls', 'awarded', 'stunning', 'ford', 'coppola', '25', 'develop', 'contrast', 'roeg', 'wih', 'intelligence', 'poetry', 'story', 'masterful', 'human', 'thinglaughi', 'disbelief', 'slavic', 'outlandish', 'array', 'memorable', 'nuts', 'dangerous', 'sweet', 'moments', 'repair', 'boss', 'genuine', 'played', 'smart', 'twist', 'shed', 'tear', 'which', 'underneath', 'malta', 'barren', 'hockey', 'defensemen', 'wide', 'net', 'ridiculous', 'relationship', 'waitress', 'stagey', 'stage', 'farce', 'pyromaniac', 'waylaid', 'laugh', 'yawn', 'barney', 'de', 'duper', 'bop', 'storm', 'trooper', 'list', 'guy', 'hes', 'shameful', 'smack', 'bonus', 'special', 'memories', 'bond', 'interesting', 'controversy', 'damian', 'modern', 'passion', 'drive', 'ireland', 'scared', 'horrified', 'situation', 'shelf', 'koteas', 'angelina', 'drago', 'cameo', 'sven', 'ole', 'thorsen', 'ebay', 'poler', 'bear', 'kinda', 'cute.but', 'question', 'fort', 'steele', 'throughout', '90', '70000', 'bell', 'higher', 'sink', 'depressing', 'god', '.stylized', 'designer', 'learn', 'politics', 'history', 'faultless', 'photography', 'brian', 'keith', 'vivid', 'member', 'sean', 'brigand', 'heroine', 'hay', 'steve', 'spiffy', 'radiant', 'ruthless', 'cando', 'lieutenant', 'stick', 'robert', 'second', 'war', 'humour', 'apt', 'brother', 'thiswhen', 'ryan', 'individual', 'tuneful', 'rita', 'hayworth', 'pedestal', 'hollywood', 'exploit', 'gain', 'nonlinear', 'thus', 'monica', 'bellucci', 'seeing', 'making', 'popular', 'laughs', 'feelgood', 'northern', 'represents', 'vivian', '95', 'her', 'role', 'european', 'throwback', 'student', '1980s', 'abroad', 'nationalities', 'different', 'fan', 'ticker', '4', 'maybe', 'hummh', 'angel', 'scamp', 'funniest', 'whenlaughcamp', 'caught', 'curtain', 'before.i', '20.the', 'lid', 'romantic', 'charming', 'junkyard', 'special.too', 'it.buy', 'chosen', 'blatant', 'american', 'propaganda', 'elsewhere', 'school', 'pile', 'round', 'values', 'continuity', 'thrown', 'corn', 'box', 'style', 'stupidity', 'proud', 'hide', 'sand', 'halfway', 'howell', '110', '010', 'premise', 'nutbag', 'notelaughid', 'stephen', 'hendrikson', 'cheekbones', 'actingeven', 'former', 'chimplike', 'tolerable', 'oyvey', 'scale', 'sake', 'brevity', 'explanation', 'both', 'amusing', 'glance', 'girlfriend', 'bela', 'lugosi', 'extraneous', 'lines', 'period', 'b', 'armand', 'already', 'ends', '810', 'score', 'spoilers', 'comprehensible', 'hang', 'camp', 'oscar', 'material', 'iq', 'mollusk', 'coming', 'insult', 'public', 'knew', 'string', 'lower', 'fox', 'scripts', 'victor', 'mclaglen', 'unrecognizable', 'taylor', 'stanwyck', 'ridiculouslaughthat', 'u.s', 'death', 'unmoving', 'singing', 'entirely', 'cheerless', 'heist', 'characterisation', 'stoic', 'chow', 'yun', 'fat', 'tomorrow', 'judo', 'la', 'woo', 'america', 'killing', 'hopeless', 'space', 'sense', 'about', '30', 'overwrought', 'gibberish', 'teen', 'goth', 'blush', 'english', 'latin', 'certainly', 'course', 'blah', 'underacting', 'falwell', 'jaclyn', 'smith', 'allstar', 'length', 'air', 'musthave', 'strident', 'blare', 'warning', 'sort', 'pap', 'afternoon', 'punish', 'jobs', 'comedy', 'universe', 'team', 'behind', 'own', 'trond', 'fausa', 'aurvåg', 'why', 'comment', '2006', 'move', 'enjoyable', 'uplifting', 'local', 'buffalo', 'lilt', 'heart', 'race', 'barcelona', 'gaudi', 'towers', 'ten', 'thoughts', 'ended', 'rough', 'draft', 'began', 'completed', 'happen', 'change', 'occur', 'idiot', 'season', 'nc17', 'final', 'zillion', 'reality', 'ratinglaugh010', 'gradelaughz', '20th', 'road', '1948', 'noir', 'edward', 'chodorov', 'produced', 'jean', 'negulesco', 'widmark', 'comical', 'unconvincing', 'constant', 'studio', 'indoor', 'exteriors', 'serious', 'start', 'martin', 'middleaged', 'upper', 'class', 'uptight', 'mistakes', 'racial', 'offend', 'overt', 'boobs', 'aside', 'major', 'filmlaughthey', 'destroy', 'steamboat', 'mickey', 'plane', 'famous', 'groundbreaking', 'crowd', 'pleaser', '1928', 'timeless', 'turkey', 'straw', 'cruel', 'among', '80', 'thug', 'diaper', 'accolades', '1947', 'masterpiece', 'garfield', 'ann', 'revere', 'lilli', 'plmer', 'william', 'conrad', 'lee', 'wong', 'howe', 'remake', 'shame', 'thomerson', 'credit', '1986', 'version', 'watchable', 'professor', 'dumb', 'meteorite', 'matthews', '1995', 'monster', 'grim', 'pace', 'lack', 'gore', 'past', 'cg', 'microsoft', 'slideshow', 'gas', 'okay', 'fair', 'critic', 'ta', 'slimy', 'teeth', 'sum', 'ebola', 'virus', 'recommended', 'charisma', 'timing', 'debits', 'popcorn', 'offensive', 'unrestrained', 'sole', 'bright', 'spot', 'recent', 'superbad', 'interim', 'offer', 'limited', 'belowpar', 'expansive', 'convey', 'broad', 'sweep', 'original', 'sign', 'asleep', 'sequel', '90s', 'wb', 'cartoons', 'vibe', 'created', 'tender', 'dark', 'teenagers', 'element', 'sit', 'through', 'fifteen', 'really', 'um', 'perabo', 'volcano', 'honest', 'foolish', 'conclusion', 'nonsense', 'painful', 'abysmal', 'vomit', 'rubbish', 'pitch', 'omit', 'ratinglaughjust', 'instant', 'credits', 'miss', 'bohemian', 'london', 'outward', 'welsh', 'coastal', 'retreat', 'friendship', 'lust', 'versus', 'concerns', 'jealousy', 'rivalry', 'heroism', 'mature', 'focus', 'keira', 'knightley', 'prone', 'closeup', 'lighting', 'footage', 'behold', 'bertolucci', 'crew', 'regardless', 'costs', 'christmas', 'errol', 'flynn', 'custer', 'olivia', 'havilland', 'fantastic', 'known', 'grew', 'jim', 'oconnor', 'dull', 'monotonous', 'guests', 'spy', 'foreign', 'random', 'taxidermists', 'stewart', 'hero', 'climax', 'lowbudget', 'nevertheless', 'stable', 'sci', 'fi', 'scot', 'entertaining', 'nonetheless', 'parts', 'delight', 'insulin', 'myself', 'task', 'south', 'africa', 'truth', 'process', 'woven', 'splendid', 'view', 'subtitles', 'shakespear', 'macbeth', 'jason', 'monolog', 'brief', 'candle', 'sphere', 'moral', 'decay', 'helen', 'evil', 'lyrics', 'dr', 'seuss', 'finest', 'award', 'effects', 'eiko', 'ishioka', 'dracula', '1971', 'format', 'miniseries', 'baaaaaad', 'collect', 'extant', 'kitchy', 'ball', 'raw', 'terror', 'lie', 'monstrous', 'consequences', 'mesmerising', 'wilkinson', 'alike', 'julian', 'treasure', 'welldone', 'phrase', 'few', 'kris', 'kristoffersen', 'difference', 'marriage', 'garage', 'facial', 'stars', 'rejection', 'park', 'southern', 'california', 'desert', 'patent', 'peter', 'miserable', 'hollow', 'garbage', 'laughable', 'angela', 'bennett', 'expert', 'pretext', 'pictures', 'begin', 'ass', 'geek', 'unbelievable', 'thumper', 'badass', 'heard', 'cole', 'mouth', 'ways', 'carol', 'sensibility', 'success', 'sydney', 'greenstreet', 'yardley', 'rpg', 'rpger', 'cuts', 'youtube', 'linelaughdont', 'comes', 'sleep', 'sobaditsgood', 'shell', 'late', 'viewing', 'title', 'scenery', 'tough', 'wonderful', 'memorized', 'fishnet', 'ham', 'fisted', 'earth', 'attention', 'watson', 'indeed', 'ordeal', 'progresses', 'anguish', 'suffering', 'reviewers', 'interview', 'lestat', 'stuart', 'townsend', 'aailiyah', 'akasha', 'mini', 'treatments', 'perplexing', 'skilled', 'meredith', 'm', 'sentiment', 'trap', 'indulgent', 'nine', 'lucio', 'fulci', 'giallo', 'subgenre', 'italian', '70s', 'standout', 'unpleasant', 'technically', 'riz', 'ortolani', 'vocal', 'distant', 'dustin', 'revealing', 'personally', 'issue', 'thick', 'ps', 'blown', 'subtle', 'rubin', 'harris', 'nervous', 'starlet', 'itself', 'coach', 'fascinating', 'snow', 'ultracheap', 'result', 'exciting', 'slightest', '1973', 'stranger', 'duet', 'astronaut', 'doctor', 'cold', 'ussr', 'scream', 'scare', 'courtroom', 'compelling', 'system', 'frightening', 'legal', 'guilt', 'innocence', 'court', 'paced', 'she', 'motivations', 'stinker', 'directtovideo', 'release', 'trek', 'v', 'frontier', 'shatner', 'nimoy', 'spock', 'kirk', 'jet', 'pack', 'mountain', 'humor', 'dosent', 'vulcan', 'uhura', 'distract', 'male', 'guards', 'opinion', 'jay', 'subject', 'neil', 'emotions', 'grainy', 'surprises', 'philippa', 'sing', 'don', 'giovanni', '18th', 'jutland', 'general', 'en', 'savor', 'impression', 'backdrop', 'notch', 'blake', 'deadpan', 'cheek', 'realistic', 'angus', 'scrimm', 'menacing', 'anatomist', 'phantasm', '40', '1949', 'lesserknown', 'juano', 'hernandez', 'lucy', 'chanceit', 'huston', 'novella', 'feelings', 'leap', 'grasp', 'portrayal', 'shortlist', 'emperor', 'spend', 'childhood', 'bigbudget', 'write', 'subplots', 'americans', 'eating', 'beall', 'further', 'nut', 'boyle', '54', 'sheer', 'tedium', 'melodrama', 'lord', 'atrocious', 'stinks', 'establish', 'subplot', 'band', 'latterday', 'whos', 'killings', 'spoil', 'writer', 'meld', 'seamless', 'union', 'creativity', 'achievement', 'celebrity', 'fame', 'forgotten', 'kevin', 'spacey', 'verbal', 'tsunami', 'ackerman', 'ages', 'younger', 'references', 'galley', 'pm', '8pm', '8.15pm', 'buildup', 'captain', 'semi', 'truck', 'linda', 'cardellini', 'shes', 'dee', 'snider', 'act', 'damn', 'suck', 'basically', 'thrillerhorror', 'miserably', 'celluloid', 'thread', 'leni', 'parker', 'anita', 'laselva', 'dislike', 'atmosphere', 'puppet', 'flicks', 'puppets', 'insomniacs', 'dreams', 'unpredictability', 'brutal', 'mystifying', 'doubt', 'moviemaking', 'warn', 'youdo', 'dumbest', 'hbo', 'hopefully', 'cox', 'win', 'jessica', 'onedimensional', 'guys', 'sculpture', 'soap', 'hip', 'paolo', 'sorrentino', 'titta', 'di', 'girolamo', 'vision', '910', 'emilio', 'debut', 'pacing', 'interplay', 'estevez', 'suggest', 'street', 'charlie', 'condescends', 'arts', 'paint', 'photograph', 'poignant', 'movieit', 'depicts', 'alert', 'meanings', 'matrix', 'provoking', 'dream', 'rickman', 'hilt', 'tract', 'raver', 'lives', 'traffic', 'wed', 'subpar', 'scientist', 'dwight', 'schultz', 'onscreen', 'chemistry', 'natural', 'gorman', 'bechard', 'homework', 'appropriate', 'each', 'track', 'threshold', 'loneliness', 'hayao', 'eighth', 'ghibili', 'gake', 'ue', 'ponyo', 'cliff', 'cgi', 'miyazaki', 'handdrawn', 'stories', 'crayonpencil', 'fanciful', 'drift', 'possible', 'surf', 'wave', '1998', 'deep', 'impact', 'armageddon', 'everywhere', 'vessel', 'taken', 'frost', 'bonuses', 'fest', 'whiny', 'brat', 'babysitting', 'march', 'judith', 'sad', 'cutie', 'confidence', 'riot', 'hugo', 'gay', 'salesman', 'darren', 'hollander', 'hoot', 'n', 'embarrassing']\n",
            "[ 0.03626981  0.04943148 -0.00586843 -0.05109369 -0.02590905 -0.08221675\n",
            "  0.09997492 -0.02068588  0.13961777  0.01266613 -0.00976586  0.03769013\n",
            " -0.15755165 -0.02240127 -0.10186106 -0.0540092   0.10663903 -0.10687702\n",
            " -0.08055283 -0.14545988]\n",
            "Word2Vec(vocab=2674, size=20, alpha=0.025)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF_PV3JwN0P6",
        "colab_type": "code",
        "outputId": "354fdbad-be2b-4584-84fe-9a9fc456d758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "print(model['you'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.10848033  0.12167265 -0.0458592  -0.20120674 -0.03437223 -0.20311394\n",
            "  0.22664073 -0.03371485  0.30419353  0.00376729  0.00348562  0.07483245\n",
            " -0.41990697 -0.04048717 -0.27936962 -0.17079318  0.21314475 -0.29875755\n",
            " -0.18865399 -0.29240727]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpOo7IrMyXZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv(\"/content/output.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5vMWS9xyjF9",
        "colab_type": "code",
        "outputId": "325ea527-f3ed-4ac1-d9e7-7ca931670342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "df1= pd.read_csv(\"output.csv\")\n",
        "df1.head(4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>['so', 'way', 'plug', 'us', 'unless', 'i', 'go...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>['good', 'case', ',', 'value', '.']</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>['great', 'jawbone', '.']</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>['charger', '45', 'minutes.major', 'problems',...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                               text  sentiment\n",
              "0           0  ['so', 'way', 'plug', 'us', 'unless', 'i', 'go...          0\n",
              "1           1                ['good', 'case', ',', 'value', '.']          1\n",
              "2           2                          ['great', 'jawbone', '.']          1\n",
              "3           3  ['charger', '45', 'minutes.major', 'problems',...          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    }
  ]
}